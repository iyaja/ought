# AUTOGENERATED! DO NOT EDIT! File to edit: 04_metrics.ipynb (unless otherwise specified).

__all__ = ['Metrics', 'EnsembleClassifier']

# Cell
class Metrics:
    def __init__(self, json='data/valid.jsonl', samples=50):
        self.samples = uniform_samples(json, samples)
        print(f"loaded {len(self.samples)} samples")

    def accuracy(self, predict_func):
        hits = []
        for sample in self.samples:
            prompt = sample['text']
            response = predict_func(prompt)

            # this portion is specific to binary AI/NOT AI classification
            # it can be replaced with a callback
            if (response.upper() == 'NOT AI'):
                pred = 'False'
            elif (response.upper() == 'AI'):
                pred = 'True'
            else:
                print(f"got invalid response: {response}")
                continue

            real = sample['label']
            hits.append(pred == real)

        return np.array(hits).sum() / len(hits)

# Cell
class EnsembleClassifier:
    def __init__(self):
        gpt_lm = GPTLMClassifier(samples=2)
        gpt_mm = GPTMatmulClassifier(samples=4)
        gpt_sm = GPTSimilarityClassifier(samples=4)
        lstm = LSTMClassifier(samples=10)
        bart = BARTClassifier(samples=4)
        self.models = [gpt_lm, gpt_mm, gpt_sm, lstm, bart]

    def predict(self, prompt):
        preds = [model.predict(prompt) for model in self.models]
        return max(set(preds), key=preds.count)