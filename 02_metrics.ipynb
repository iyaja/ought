{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "combined-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-horizon",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Generic utility functions to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excellent-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ought.starter import *\n",
    "from ought.lstm import LSTMClassifier\n",
    "from ought.starter import GPTClassifier\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-tennis",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-assets",
   "metadata": {},
   "source": [
    "One of the first orders of buisness is setting up a clear objective to optimize. Here, the goal is to get as high an accuracy as possible on text classification on the test set, so the metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wireless-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Metrics:\n",
    "    def __init__(self, train_path='data/train.jsonl', valid_path='data/dev.jsonl'):\n",
    "        self.train = load_jsonl(train_path)\n",
    "        self.valid = load_jsonl(valid_path)\n",
    "        print(f\"loaded {len(self.valid)} examples\")\n",
    "        \n",
    "    def accuracy(self, predict_func, samples=20):\n",
    "        INSTRUCTIONS = 'Label each of the following examples as \"AI\" or \"NOT AI\"'\n",
    "        \n",
    "        hits = []\n",
    "        for i, sample in enumerate(self.valid):\n",
    "            if i > samples: break\n",
    "            # prompt = make_prompt(INSTRUCTIONS, self.valid[i - 5:i], self.valid[i])\n",
    "            prompt = sample['text']\n",
    "            response = predict_func(prompt)\n",
    "            if (response.upper() == 'NOT AI'):\n",
    "                pred = 'False'\n",
    "            elif (response.upper() == 'AI'):\n",
    "                pred = 'True'\n",
    "            else:\n",
    "                print(f\"got invalid response: {response}\")\n",
    "                continue\n",
    "                \n",
    "            real = self.valid[i]['label']\n",
    "            hits.append(pred == real)\n",
    "        \n",
    "        return np.array(hits).sum() / len(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advisory-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 500 examples\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hawaiian-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy(lambda _: 'Not AI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-programming",
   "metadata": {},
   "source": [
    "## GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 s, sys: 51.6 ms, total: 2.48 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "model = GPTClassifier()\n",
    "acc = metrics.accuracy(model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dependent-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-recipe",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "model = LSTMClassifier()\n",
    "acc = metrics.accuracy(model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-fleece",
   "metadata": {},
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "model = BARTClassifier()\n",
    "acc = metrics.accuracy(model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
