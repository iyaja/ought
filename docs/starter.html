---

title: Ought Text Classification Project


keywords: fastai
sidebar: home_sidebar

summary: "Binary classification on scientific paper abstracts"
description: "Binary classification on scientific paper abstracts"
nb_path: "01_starter.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_starter.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="GPT-2-Prompt-Manipulation">GPT-2 Prompt Manipulation<a class="anchor-link" href="#GPT-2-Prompt-Manipulation"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The simplest approach is to to feed in a small number of trainging examples into the prompt directly for zero-shot classification.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>GPT2LMHeadModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (3): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (4): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (5): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (6): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (7): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (8): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (9): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (10): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (11): Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50257, bias=False)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Utilities">Utilities<a class="anchor-link" href="#Utilities"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate" class="doc_header"><code>generate</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L12" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate</code>(<strong><code>prompt</code></strong>, <strong><code>max_length</code></strong>=<em><code>5</code></em>, <strong><code>stop_token</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_logits_and_tokens</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">input_id</span><span class="p">])</span> <span class="k">for</span> <span class="n">input_id</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tokens</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">EXAMPLE_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Horrible: negative</span>
<span class="s2">Great: positive</span>
<span class="s2">Bad:&quot;&quot;&quot;</span>

<span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">EXAMPLE_PROMPT</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">generated_text</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;Horrible: negative\nGreat: positive\nBad: negative&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logits</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">get_logits_and_tokens</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
<span class="n">last_token_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">negative_prob</span> <span class="o">=</span> <span class="n">last_token_probs</span><span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot; negative&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">positive_prob</span> <span class="o">=</span> <span class="n">last_token_probs</span><span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot; positive&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="se">\n</span><span class="s2">negative prob: </span><span class="si">{</span><span class="n">negative_prob</span><span class="si">}</span><span class="se">\n</span><span class="s2">positive prob: </span><span class="si">{</span><span class="n">positive_prob</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tokens: [&#39;Hor&#39;, &#39;rible&#39;, &#39;:&#39;, &#39; negative&#39;, &#39;\n&#39;, &#39;Great&#39;, &#39;:&#39;, &#39; positive&#39;, &#39;\n&#39;, &#39;Bad&#39;, &#39;:&#39;, &#39; negative&#39;]
negative prob: 0.7252255082130432
positive prob: 0.11788686364889145
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-Data">Load Data<a class="anchor-link" href="#Load-Data"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Define helper function to load text from <code>.jsonl</code> files.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_jsonl" class="doc_header"><code>load_jsonl</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L20" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_jsonl</code>(<strong><code>filename</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_examples</span> <span class="o">=</span> <span class="n">load_jsonl</span><span class="p">(</span><span class="s2">&quot;data/train.jsonl&quot;</span><span class="p">)</span>
<span class="n">train_examples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;label&#39;: &#39;False&#39;,
 &#39;text&#39;: &#39;non relativistic approach for cosmological scalar field dark matter. we derive non relativistic equations of motion for the formation of cosmological structure in a scalar field dark matter sfdm model corresponding to a complex scalar field endowed with a quadratic scalar potential. starting with the full equations of motion written in the newtonian gauge of scalar perturbations we separate out the fields involved into relativistic and non relativistic parts and find the equations of motion for the latter that can be used to build up the full solution. one important assumption will also be that the sfdm field is in the regime of fast oscillations under which its behavior is exactly that of cold dark matter. the resultant equations are quite similar to the schr odinger poisson system of newtonian boson stars plus relativistic leftovers. we exploit that similarity to show how to simulate with minimum numerical effort the formation of cosmological structure in sfdm models and others alike and ultimately prove their viability as complete dark matter models.&#39;,
 &#39;meta&#39;: {&#39;id&#39;: &#39;1310.8601&#39;, &#39;year&#39;: 2013}}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="render_example" class="doc_header"><code>render_example</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>render_example</code>(<strong><code>example</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="render_end_example" class="doc_header"><code>render_end_example</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L31" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>render_end_example</code>(<strong><code>example</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="make_prompt" class="doc_header"><code>make_prompt</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L37" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>make_prompt</code>(<strong><code>instructions</code></strong>, <strong><code>train_examples</code></strong>, <strong><code>end_example</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">INSTRUCTIONS</span> <span class="o">=</span> <span class="s2">&quot;Classify the following examples based on whether they are AI-relevant or not:&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">make_prompt</span><span class="p">(</span><span class="n">INSTRUCTIONS</span><span class="p">,</span> <span class="n">train_examples</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="n">train_examples</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Classify the following examples based on whether they are AI-relevant or not:

TITLE: thermodynamic analysis of quantum error correcting engines
ABSTRACT: quantum error correcting codes can be cast in a way which is strikingly similar to a quantum heat engine undergoing an otto cycle. in this paper we strengthen this connection further by carrying out a complete assessment of the thermodynamic properties of strokes operator based error correcting codes. this includes an expression for the entropy production in the cycle which as we show contains clear contributions stemming from the different sources of irreversibility. to illustrate our results we study a classical qubit error correcting code well suited for incoherent states and the qubit shor code capable of handling fully quantum states. we show that the work cost associated with the correction gate is directly associated with the heat introduced by the error. moreover the work cost associated with encoding decoding quantum information is always positive a fact which is related to the intrinsic irreversibility introduced by the noise. finally we find that correcting the coherent and thus genuinely quantum part of a quantum state introduces substantial modifications related to the hadamard gates required to encode and decode coherences.
LABEL: NOT AI

--

TITLE: nlo qcd corrections to wzjj production at the lhc
ABSTRACT: we present a summary of the first calculation of nlo qcd corrections to wzjj production with leptonic decays at the lhc. our results show that the next to leading order corrections reduce significantly the scale uncertainties.
LABEL: NOT AI

--

TITLE: asymptotics for lipschitz percolation above tilted planes
ABSTRACT: we consider lipschitz percolation in dimensions above planes tilted by an angle along one or several coordinate axes. in particular we are interested in the asymptotics of the critical probability as as well as our principal results show that the convergence of the critical probability to is polynomial as and in addition we identify the correct order of this polynomial convergence and in we also obtain the correct prefactor.
LABEL: NOT AI

--

TITLE: the colored jones polynomials for bridge links
ABSTRACT: kuperberg introduced web spaces for some lie algebras which are generalizations of the kauffman bracket skein module on a disk with marked points. we derive some formulas for and clasped web spaces by graphical calculus using skein theory. these formulas are colored version of skein relations twist formulas and bubble skein expansion formulas. we calculate the and colored jones polynomials of bridge knots and links explicitly using twist formulas.
LABEL: NOT AI

--

TITLE: population mixtures and searches of lensed and extended quasars across photometric surveys
ABSTRACT: wide field photometric surveys enable searches of rare yet interesting objects such as strongly lensed quasars or quasars with a bright host galaxy. past searches for lensed quasars based on their optical and near infrared properties have relied on photometric cuts and spectroscopic pre selection as in the sloan quasar lens search or neural networks applied to photometric samples. these methods rely on cuts in morphology and colours with the risk of losing many interesting objects due to scatter in their population properties restrictive training sets systematic uncertainties in catalog based magnitudes and survey to survey photometric variations. here we explore the performance of a gaussian mixture model to separate point like quasars quasars with an extended host and strongly lensed quasars using griz psf and model magnitudes and wise w1 w2. the choice of optical magnitudes is due to their presence in all current and upcoming releases of wide field surveys whereas uv information is not always available. we then assess the contamination from blue galaxies and the role of additional features such as w3 magnitudes or psf model terms as morphological information. as a demonstration we conduct a search in a random of the sdss footprint and we provide the catalog of the sdss object with the highest `lens score in our selection that survive visual inspection and are spectroscopically confirmed to host active nuclei. we inspect archival data and find images of objects in the hubble legacy archive including known lenses. the code and materials are available to facilitate follow up.
LABEL:
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Classify the following examples based on whether they are AI-relevant or not:

TITLE: thermodynamic analysis of quantum error correcting engines
ABSTRACT: quantum error correcting codes can be cast in a way which is strikingly similar to a quantum heat engine undergoing an otto cycle. in this paper we strengthen this connection further by carrying out a complete assessment of the thermodynamic properties of strokes operator based error correcting codes. this includes an expression for the entropy production in the cycle which as we show contains clear contributions stemming from the different sources of irreversibility. to illustrate our results we study a classical qubit error correcting code well suited for incoherent states and the qubit shor code capable of handling fully quantum states. we show that the work cost associated with the correction gate is directly associated with the heat introduced by the error. moreover the work cost associated with encoding decoding quantum information is always positive a fact which is related to the intrinsic irreversibility introduced by the noise. finally we find that correcting the coherent and thus genuinely quantum part of a quantum state introduces substantial modifications related to the hadamard gates required to encode and decode coherences.
LABEL: NOT AI

--

TITLE: nlo qcd corrections to wzjj production at the lhc
ABSTRACT: we present a summary of the first calculation of nlo qcd corrections to wzjj production with leptonic decays at the lhc. our results show that the next to leading order corrections reduce significantly the scale uncertainties.
LABEL: NOT AI

--

TITLE: asymptotics for lipschitz percolation above tilted planes
ABSTRACT: we consider lipschitz percolation in dimensions above planes tilted by an angle along one or several coordinate axes. in particular we are interested in the asymptotics of the critical probability as as well as our principal results show that the convergence of the critical probability to is polynomial as and in addition we identify the correct order of this polynomial convergence and in we also obtain the correct prefactor.
LABEL: NOT AI

--

TITLE: the colored jones polynomials for bridge links
ABSTRACT: kuperberg introduced web spaces for some lie algebras which are generalizations of the kauffman bracket skein module on a disk with marked points. we derive some formulas for and clasped web spaces by graphical calculus using skein theory. these formulas are colored version of skein relations twist formulas and bubble skein expansion formulas. we calculate the and colored jones polynomials of bridge knots and links explicitly using twist formulas.
LABEL: NOT AI

--

TITLE: population mixtures and searches of lensed and extended quasars across photometric surveys
ABSTRACT: wide field photometric surveys enable searches of rare yet interesting objects such as strongly lensed quasars or quasars with a bright host galaxy. past searches for lensed quasars based on their optical and near infrared properties have relied on photometric cuts and spectroscopic pre selection as in the sloan quasar lens search or neural networks applied to photometric samples. these methods rely on cuts in morphology and colours with the risk of losing many interesting objects due to scatter in their population properties restrictive training sets systematic uncertainties in catalog based magnitudes and survey to survey photometric variations. here we explore the performance of a gaussian mixture model to separate point like quasars quasars with an extended host and strongly lensed quasars using griz psf and model magnitudes and wise w1 w2. the choice of optical magnitudes is due to their presence in all current and upcoming releases of wide field surveys whereas uv information is not always available. we then assess the contamination from blue galaxies and the role of additional features such as w3 magnitudes or psf model terms as morphological information. as a demonstration we conduct a search in a random of the sdss footprint and we provide the catalog of the sdss object with the highest `lens score in our selection that survive visual inspection and are spectroscopically confirmed to host active nuclei. we inspect archival data and find images of objects in the hubble legacy archive including known lenses. the code and materials are available to facilitate follow up.
LABEL: NOT AI
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extra-Helper-Function">Extra Helper Function<a class="anchor-link" href="#Extra-Helper-Function"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are some extra utility functions that were not defined in the original starter code, but were still useful.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">load_jsonl</span><span class="p">(</span><span class="s2">&quot;data/train.jsonl&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Collect some random samples across classes. This should be flexible enough to generalize beyong the <code>'AI'</code> and <code>'Not AI'</code> labels.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;False&#39;, &#39;True&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">samples_per_label</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="n">label</span><span class="p">]</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="n">samples_per_label</span><span class="p">]</span>
    <span class="n">samples</span> <span class="o">+=</span> <span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">]</span>
<span class="n">samples</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;label&#39;: &#39;False&#39;,
  &#39;text&#39;: &#39;thermodynamic analysis of quantum error correcting engines. quantum error correcting codes can be cast in a way which is strikingly similar to a quantum heat engine undergoing an otto cycle. in this paper we strengthen this connection further by carrying out a complete assessment of the thermodynamic properties of strokes operator based error correcting codes. this includes an expression for the entropy production in the cycle which as we show contains clear contributions stemming from the different sources of irreversibility. to illustrate our results we study a classical qubit error correcting code well suited for incoherent states and the qubit shor code capable of handling fully quantum states. we show that the work cost associated with the correction gate is directly associated with the heat introduced by the error. moreover the work cost associated with encoding decoding quantum information is always positive a fact which is related to the intrinsic irreversibility introduced by the noise. finally we find that correcting the coherent and thus genuinely quantum part of a quantum state introduces substantial modifications related to the hadamard gates required to encode and decode coherences.&#39;,
  &#39;meta&#39;: {&#39;id&#39;: &#39;1911.06354&#39;, &#39;year&#39;: 2019}},
 {&#39;label&#39;: &#39;False&#39;,
  &#39;text&#39;: &#39;nlo qcd corrections to wzjj production at the lhc. we present a summary of the first calculation of nlo qcd corrections to wzjj production with leptonic decays at the lhc. our results show that the next to leading order corrections reduce significantly the scale uncertainties.&#39;,
  &#39;meta&#39;: {&#39;id&#39;: &#39;1310.4369&#39;, &#39;year&#39;: 2013}},
 {&#39;label&#39;: &#39;True&#39;,
  &#39;text&#39;: &#39;norec the norwegian review corpus. this paper presents the norwegian review corpus norec created for training and evaluating models for document level sentiment analysis. the full text reviews have been collected from major norwegian news sources and cover a range of different domains including literature movies video games restaurants music and theater in addition to product reviews across a range of categories. each review is labeled with a manually assigned score of as provided by the rating of the original author. this first release of the corpus comprises more than reviews. it is distributed using the conll u format pre processed using udpipe along with a rich set of metadata. the work reported in this paper forms part of the sant initiative sentiment analysis for norwegian text a project seeking to provide resources and tools for sentiment analysis and opinion mining for norwegian. as resources for sentiment analysis have so far been unavailable for norwegian norec represents a highly valuable and sought after addition to norwegian language technology.&#39;,
  &#39;meta&#39;: {&#39;id&#39;: &#39;1710.05370&#39;, &#39;year&#39;: 2017}},
 {&#39;label&#39;: &#39;True&#39;,
  &#39;text&#39;: &#39;a new local adaptive thresholding technique in binarization. image binarization is the process of separation of pixel values into two groups white as background and black as foreground. thresholding plays a major in binarization of images. thresholding can be categorized into global thresholding and local thresholding. in images with uniform contrast distribution of background and foreground like document images global thresholding is more appropriate. in degraded document images where considerable background noise or variation in contrast and illumination exists there exists many pixels that cannot be easily classified as foreground or background. in such cases binarization with local thresholding is more appropriate. this paper describes a locally adaptive thresholding technique that removes background by using local mean and mean deviation. normally the local mean computational time depends on the window size. our technique uses integral sum image as a prior processing to calculate local mean. it does not involve calculations of standard deviations as in other local adaptive techniques. this along with the fact that calculations of mean is independent of window size speed up the process as compared to other local thresholding techniques.&#39;,
  &#39;meta&#39;: {&#39;id&#39;: &#39;1201.5227&#39;, &#39;year&#39;: 2012}}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="uniform_samples" class="doc_header"><code>uniform_samples</code><a href="https://github.com/iyaja/ought/tree/main/ought/starter.py#L48" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>uniform_samples</code>(<strong><code>json</code></strong>=<em><code>'data/train.jsonl'</code></em>, <strong><code>n_samples</code></strong>=<em><code>2</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

