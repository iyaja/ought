---

title: BART Zero-Shot Prediction Classification 


keywords: fastai
sidebar: home_sidebar

summary: "Using modern zero-shot classification techniques"
description: "Using modern zero-shot classification techniques"
nb_path: "04_bart.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 04_bart.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The starter code is helpful, but Huggingface has built-in tools for zero shot classification. This also makes it easier to test different models (some may be trained on a larger amount of scientific text, which will be helpful).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, we'll use FaceBook's <a href="https://huggingface.co/facebook/bart-large-mnli">BART</a> model. It was explicitly designed for zero-shot text classification (among other tasks), and should work well out of the box. The same prompts as GPT-2 are used for consistency, though there is potentially some scope for tuning here.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clas</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;zero-shot-classification&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;AI&quot;</span><span class="p">,</span> <span class="s2">&quot;Not AI&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">load_jsonl</span><span class="p">(</span><span class="s2">&quot;data/train.jsonl&quot;</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">make_prompt</span><span class="p">(</span><span class="s1">&#39;Label each of the following examples as &quot;AI&quot; or &quot;NOT AI&quot;&#39;</span><span class="p">,</span> <span class="n">samples</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">clas</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Refactor-into-a-Single-Class">Refactor into a Single Class<a class="anchor-link" href="#Refactor-into-a-Single-Class"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can refactor all this and export it as a single class with two useful methods:</p>
<ul>
<li>An initializer that will retrain a new model for <em>every</em> new instance. This is intended, since we do not know the training set ahead of time. One potential improvement here would be to continuously train on every new <code>.jsonl</code> file that comes in and save the weights, but there is not enough data for that here. </li>
<li>A <code>predict</code> method that takes in a sentence and returns a prediction by querying the trained model.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BARTClassifier" class="doc_header"><code>class</code> <code>BARTClassifier</code><a href="https://github.com/iyaja/ought/tree/main/ought/bart.py#L10" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BARTClassifier</code>(<strong><code>instructions</code></strong>=<em><code>'Label each of the following examples as "AI" or "NOT AI"'</code></em>, <strong><code>json</code></strong>=<em><code>'data/train.jsonl'</code></em>, <strong><code>samples</code></strong>=<em><code>2</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='you might have to restart the notebook to clear GPU memory at this point' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">load_jsonl</span><span class="p">(</span><span class="s2">&quot;data/test_no_labels.jsonl&quot;</span><span class="p">)</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
<span class="n">prompt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;out of plane effect on the superconductivity of sr2 xbaxcuo3+d with tc up to 98k. we comment on the paper published by w.b. gao q.q. liu l.x. yang y.yu f.y. li c.q. jin and s. uchida in phys. rev. b and give alternate explanations for the enhanced superconductivity. the enhanced onset tc of 98k observed upon substituting ba for sr is attributed to optimal oxygen ordering rather than to the increase in volume. comparison with la2cuo +x samples suggest that the effect of disorder is overestimated.&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">clas</span> <span class="o">=</span> <span class="n">BARTClassifier</span><span class="p">()</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">clas</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: [&#39;model.encoder.version&#39;, &#39;model.decoder.version&#39;]
- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: [&#39;model.encoder.version&#39;, &#39;model.decoder.version&#39;]
- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 22.9 s, sys: 1.16 s, total: 24.1 s
Wall time: 24.5 s
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;Not AI&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

